theano-lstm gradient descent theano lstm neural network sequence sequence dropout function usage gradient gradient layer matrix randomly random theano-lstm-recurrent-network different hidden mask masked mask minibatch label label optimizers optimizer optimize computation compute input input length length network follow follow output output forward variable variable loop multiplies multiply elementwise pad pad pad y n th